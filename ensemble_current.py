# -*- coding: utf-8 -*-
"""mlp_bert_combined.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L7qnwkgMW5eWVMiemBS6q4PVXdf97TA1
"""

!pip install transformers
from sklearn.preprocessing import MinMaxScaler
import os
from sklearn.metrics import confusion_matrix
import keras
import sklearn
import tempfile
from sklearn.model_selection import StratifiedKFold
import tensorflow as tf
from sklearn.preprocessing import *
import pandas as pd
import matplotlib as mpl
import re
import matplotlib.pyplot as plt
from keras import backend as kf
import numpy as np
import seaborn as sns
import string 
from sklearn.utils import class_weight
from sklearn.model_selection import train_test_split
import os
from transformers import BertTokenizer, TFBertModel
from transformers import DebertaTokenizer, TFDebertaForMaskedLM
from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig
from keras import backend as K
import inflect
from keras import regularizers
import sklearn as sk

#colors for confusion matrix
colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

#load tokenizer
#tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")

# load dataset
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/jti_dataset_refined.csv')


#define strategy for gpu distributed workload sclaes with number of gpus available
#strategy = tf.distribute.MirroredStrategy()
#strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
#gpus = tf.config.list_logical_devices('GPU')
tf.config.set_soft_device_placement(True)
strategy = strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))
#define maxlength of bert vector
MAXLEN = 100

#copy dataset to have one original

def text_clean(x):
    ### Light
    x = x.lower() # lowercase everything
    x = x.encode('ascii', 'ignore').decode()  # remove unicode characters
    x = re.sub(r'https*\S+', ' ', x) # remove links
    x = re.sub(r'http*\S+', ' ', x)
    # cleaning up text
    return x


print(df['Cleaned_Idea_Description'][2314])
df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(text_clean)
print(df['Cleaned_Idea_Description'][2314])

# import the inflect library

p = inflect.engine()
 
# convert number into words
def convert_number(text):
    # split string into list of words
    temp_str = text.split()
    # initialise empty list
    new_string = []
 
    for word in temp_str:
        # if word is a digit, convert the digit
        # to numbers and append into the new_string list
        if word.isdigit():
            temp = p.number_to_words(word)
            new_string.append(temp)
 
        # append the word as it is
        else:
            new_string.append(word)
 
    # join the words of new_string to form a string
    temp_str = ' '.join(new_string)
    return temp_str


df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(convert_number)
print(df['Cleaned_Idea_Description'][2314])

# remove punctuation
def remove_punctuation(text):
    translator = str.maketrans('', '', string.punctuation)
    return text.translate(translator)

# remove whitespace from text
def remove_whitespace(text):
    return  " ".join(text.split())


df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(remove_whitespace)
print(df['Cleaned_Idea_Description'][2314])

# ratio of good to bad ideas
neg, pos = np.bincount(df['top_ideas'])
total = neg + pos
print('Examples:\n    Total: {}\n    Positive: {} ({:.2f}% of total)\n'.format(
    total, pos, 100 * pos / total))

weight_for_0 = (1 / neg) * (total / 2.0)
weight_for_1 = ((1 / pos) * (total / 2.0))


# calculate class weights
class_weight = {0: weight_for_0, 1: weight_for_1}
# calculate class weights
print('Weight for class 0: {:.2f}'.format(weight_for_0))
print('Weight for class 1: {:.2f}'.format(weight_for_1))

#calculate initial weights
initial_bias = np.log([pos/neg])
#colors for confusion matrix
colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

#load tokenizer
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# load dataset
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/jti_dataset_refined.csv')


#define strategy for gpu distributed workload sclaes with number of gpus available
#strategy = tf.distribute.MirroredStrategy()
#strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
#gpus = tf.config.list_logical_devices('GPU')
tf.config.set_soft_device_placement(True)
strategy = strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))
#define maxlength of bert vector
MAXLEN = 100

#copy dataset to have one original

def text_clean(x):
    ### Light
    x = x.lower() # lowercase everything
    x = x.encode('ascii', 'ignore').decode()  # remove unicode characters
    x = re.sub(r'https*\S+', ' ', x) # remove links
    x = re.sub(r'http*\S+', ' ', x)
    # cleaning up text
    return x


print(df['Cleaned_Idea_Description'][2314])
df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(text_clean)
print(df['Cleaned_Idea_Description'][2314])

# import the inflect library

p = inflect.engine()
 
# convert number into words
def convert_number(text):
    # split string into list of words
    temp_str = text.split()
    # initialise empty list
    new_string = []
 
    for word in temp_str:
        # if word is a digit, convert the digit
        # to numbers and append into the new_string list
        if word.isdigit():
            temp = p.number_to_words(word)
            new_string.append(temp)
 
        # append the word as it is
        else:
            new_string.append(word)
 
    # join the words of new_string to form a string
    temp_str = ' '.join(new_string)
    return temp_str


df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(convert_number)
print(df['Cleaned_Idea_Description'][2314])

# remove punctuation
def remove_punctuation(text):
    translator = str.maketrans('', '', string.punctuation)
    return text.translate(translator)

# remove whitespace from text
def remove_whitespace(text):
    return  " ".join(text.split())


df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(remove_whitespace)
print(df['Cleaned_Idea_Description'][2314])

# ratio of good to bad ideas
neg, pos = np.bincount(df['top_ideas'])
total = neg + pos
print('Examples:\n    Total: {}\n    Positive: {} ({:.2f}% of total)\n'.format(
    total, pos, 100 * pos / total))

weight_for_0 = (1 / neg) * (total / 2.0)
weight_for_1 = ((1 / pos) * (total / 2.0))


# calculate class weights
class_weight = {0: weight_for_0, 1: weight_for_1}
# calculate class weights
print('Weight for class 0: {:.2f}'.format(weight_for_0))
print('Weight for class 1: {:.2f}'.format(weight_for_1))

#calculate initial weights
initial_bias = np.log([pos/neg])

#hyperparameters for training
MAXLEN = MAXLEN
BATCH_SIZE_PER_REPLICA = 64
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
EPOCHS = 50
DROPOUT=0.3
LEARNING_RATE = 3e-5
REGULARIZATION = 0.01
DATA_LENGTH = len(df)

class CustomCallback(keras.callbacks.Callback):
    def on_train_begin(self, logs=None):
        keys = list(logs.keys())
        print("Starting training; got log keys: {}".format(keys))

    def on_train_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop training; got log keys: {}".format(keys))

    def on_epoch_begin(self, epoch, logs=None):
        keys = list(logs.keys())
        print("Start epoch {} of training; got log keys: {}".format(epoch, keys))

    def on_epoch_end(self, epoch, logs=None):
        keys = list(logs.keys())
        print("End epoch {} of training; got log keys: {}".format(epoch, keys))

    def on_test_begin(self, logs=None):
        keys = list(logs.keys())
        print("Start testing; got log keys: {}".format(keys))

    def on_test_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop testing; got log keys: {}".format(keys))

    def on_predict_begin(self, logs=None):
        keys = list(logs.keys())
        print("Start predicting; got log keys: {}".format(keys))

    def on_predict_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop predicting; got log keys: {}".format(keys))

    def on_train_batch_begin(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Training: start of batch {}; got log keys: {}".format(batch, keys))

    def on_train_batch_end(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Training: end of batch {}; got log keys: {}".format(batch, keys))

    def on_test_batch_begin(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Evaluating: start of batch {}; got log keys: {}".format(batch, keys))

    def on_test_batch_end(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Evaluating: end of batch {}; got log keys: {}".format(batch, keys))

    def on_predict_batch_begin(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Predicting: start of batch {}; got log keys: {}".format(batch, keys))

    def on_predict_batch_end(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Predicting: end of batch {}; got log keys: {}".format(batch, keys))

class EarlyStoppingAtMinLoss(keras.callbacks.Callback):
    """Stop training when the loss is at its min, i.e. the loss stops decreasing.

  Arguments:
      patience: Number of epochs to wait after min has been hit. After this
      number of no improvement, training stops.
  """

    def __init__(self, patience=0):
        super(EarlyStoppingAtMinLoss, self).__init__()
        self.patience = patience
        self.epoch = 0
        self.sp = []
        self.recall = []
        self.accuracy = []
        self.sp_val = []
        self.recall_val = []
        self.accuracy_val = []
        # best_weights to store the weights at which the minimum loss occurs.
        self.best_weights = None

    def on_train_begin(self, logs=None):
        # The number of epoch it has waited when loss is no longer minimum.
        self.wait = 0
        # The epoch the training stops at.
        self.stopped_epoch = 0
        # Initialize the best as infinity.
        self.best = 0

    def on_epoch_end(self, epoch, logs=None):
        self.sp.append(logs.get("special_metric"))
        self.recall.append(logs.get("recall"))
        self.accuracy.append(logs.get("accuracy"))

        self.epoch = epoch

        self.sp_val.append(logs.get("val_special_metric"))
        self.recall_val.append(logs.get("val_recall"))
        self.accuracy_val.append(logs.get("val_accuracy"))
        print("recall_train:\n")
        print(self.recall)
        print("recall_val:\n")
        print( self.recall_val)

        try:
          if self.sp_val[epoch] < self.sp_val[epoch-1]:
            if self.recall[epoch] <0.8 or self.accuracy[epoch] < 0.8:
              pass
            elif self.recall_val[epoch]>self.recall_val[epoch-1]:
              pass
            else:
              if self.sp_val[epoch-1]>self.sp_val[epoch-2] and self.sp_val[epoch]>self.sp_val[epoch-2]:
                pass
              else:
                self.model.stop_training = True
                self.stopped_epoch = epoch
                print("Restoring model weights from the end of the best epoch.")
                self.model.set_weights(self.best_weights)
          else:
            if self.sp_val[epoch] > self.best:
              self.best_weights = self.model.get_weights()
        except TypeError:
          print("first_round")


    def on_train_end(self, logs=None):
        if self.stopped_epoch > 0:
            print("Epoch %05d: early stopping\n" % (self.stopped_epoch + 1))

class EarlyStoppingAtMinLoss_mlp(keras.callbacks.Callback):
    """Stop training when the loss is at its min, i.e. the loss stops decreasing.

  Arguments:
      patience: Number of epochs to wait after min has been hit. After this
      number of no improvement, training stops.
  """

    def __init__(self, patience=0):
        super(EarlyStoppingAtMinLoss_mlp, self).__init__()
        self.patience = patience
        self.epoch = 0
        self.sp = []
        self.recall = []
        self.accuracy = []
        self.sp_val = []
        self.recall_val = []
        self.accuracy_val = []
        # best_weights to store the weights at which the minimum loss occurs.
        self.best_weights = None

    def on_train_begin(self, logs=None):
        # The number of epoch it has waited when loss is no longer minimum.
        self.wait = 0
        # The epoch the training stops at.
        self.stopped_epoch = 0
        # Initialize the best as infinity.
        self.best = 0

    def on_epoch_end(self, epoch, logs=None):
        self.sp.append(logs.get("special_metric"))
        self.recall.append(logs.get("recall"))
        self.accuracy.append(logs.get("accuracy"))

        self.epoch = epoch

        self.sp_val.append(logs.get("val_special_metric"))
        self.recall_val.append(logs.get("val_recall"))
        self.accuracy_val.append(logs.get("val_accuracy"))
        print("recall_train:\n")
        print(self.recall)
        print("recall_val:\n")
        print( self.recall_val)

        try:
          if self.sp_val[epoch] < self.sp_val[epoch-1]:
            if self.recall[epoch] <0.75 or self.accuracy[epoch] < 0.75:
              pass
            elif self.recall_val[epoch]>self.recall_val[epoch-1]:
              pass
            else:
              if self.sp_val[epoch-1]>self.sp_val[epoch-2] and self.sp_val[epoch]>self.sp_val[epoch-2]:
                pass
              else:
                self.model.stop_training = True
                self.stopped_epoch = epoch
                print("Restoring model weights from the end of the best epoch.")
                self.model.set_weights(self.best_weights)
          else:
            if self.sp_val[epoch] > self.best:
              self.best_weights = self.model.get_weights()
        except TypeError:
          print("first_round")


    def on_train_end(self, logs=None):
        if self.stopped_epoch > 0:
            print("Epoch %05d: early stopping\n" % (self.stopped_epoch + 1))

class Special_Metric(tf.keras.metrics.Metric):

  def __init__(self, name='special_metric', **kwargs):
    super(Special_Metric, self).__init__(name=name, **kwargs)
    self.true_positives = self.add_weight(name='tp', initializer='zeros')
    self.false_positives = self.add_weight(name='fp', initializer='zeros')
    self.true_negatives = self.add_weight(name='tn', initializer='zeros')
    self.false_negatives = self.add_weight(name='fn', initializer='zeros')

  def update_state(self, y_true, y_pred, sample_weight=None):
    y_true = tf.cast(y_true, tf.float32)
    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))
    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))
    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))

    self.true_positives.assign_add(tp)
    self.false_positives.assign_add(fp)
    self.true_negatives.assign_add(tn)
    self.false_negatives.assign_add(fn)

  def result(self):
    recall = self.true_positives / (self.true_positives + self.false_negatives)
    accuracy = (self.true_positives+ self.true_negatives) / (self.true_positives + self.false_negatives + self.true_negatives + self.false_positives)
    special = (1.3*recall + accuracy) *0.43
    return special

  def reset_state(self):
    self.true_positives.assign(0)
    self.false_positives.assign(0)
    self.true_negatives.assign(0)
    self.false_negatives.assign(0)

class F1(tf.keras.metrics.Metric):

  def __init__(self, name='F1', **kwargs):
    super(F1, self).__init__(name=name, **kwargs)
    self.true_positives = self.add_weight(name='tp', initializer='zeros')
    self.false_positives = self.add_weight(name='fp', initializer='zeros')
    self.true_negatives = self.add_weight(name='tn', initializer='zeros')
    self.false_negatives = self.add_weight(name='fn', initializer='zeros')

  def update_state(self, y_true, y_pred, sample_weight=None):
    y_true = tf.cast(y_true, tf.float32)
    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))
    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))
    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))

    self.true_positives.assign_add(tp)
    self.false_positives.assign_add(fp)
    self.true_negatives.assign_add(tn)
    self.false_negatives.assign_add(fn)

  def result(self):
    recall = self.true_positives / (self.true_positives + self.false_negatives)
    precision = self.true_positives / (self.true_positives + self.false_positives)
    f1 = 2 * precision * recall / (precision + recall)
    return f1

  def reset_state(self):
    self.true_positives.assign(0)
    self.false_positives.assign(0)
    self.true_negatives.assign(0)
    self.false_negatives.assign(0)

with strategy.scope():
    METRICS = [
        keras.metrics.TruePositives(name='tp'),
        keras.metrics.FalsePositives(name='fp'),
        keras.metrics.TrueNegatives(name='tn'),
        keras.metrics.FalseNegatives(name='fn'),
        keras.metrics.Recall(name='recall'),
        keras.metrics.BinaryAccuracy(name='accuracy'),
        tf.keras.metrics.Precision(name='precision'),
        keras.metrics.AUC(name='auc'),
        keras.metrics.AUC(name='prc', curve='PR'),
        Special_Metric()
]

DISTILBERT_DROPOUT = 0.3
DISTILBERT_ATT_DROPOUT = 0.3
# Configure DistilBERT's initialization
config = DistilBertConfig(dropout=DISTILBERT_DROPOUT, 
                          attention_dropout=DISTILBERT_ATT_DROPOUT, 
                          output_hidden_states=True)

#mlp for metadata classification
def build_mlp(metrics=METRICS):
    output_bias = tf.keras.initializers.Constant(initial_bias)
    input = keras.Input(shape=(6, ))
    layer1= Dense(128, activation='relu', 
                kernel_initializer='random_normal')(input)
    dropout1 = keras.layers.Dropout(0.2)(layer1)
    layer2 = Dense(64,activation='relu',kernel_initializer='random_normal')(dropout1)
    dropout2 = keras.layers.Dropout(0.2)(layer2)
    layer3 = Dense(32,activation='relu',kernel_initializer='random_normal')(dropout2)
    output = Dense(1,activation='sigmoid',kernel_initializer='random_normal',bias_initializer=output_bias)(layer3)
    model = tf.keras.models.Model(inputs=input, outputs=output)
    model.compile(
      optimizer=keras.optimizers.Adam(learning_rate=1e-3),
      loss=keras.losses.BinaryCrossentropy(),
      metrics=metrics)
    return model

#bert for text classification (as in Devlin et al. 2016)
def build_bert(transformer, max_len=MAXLEN):
    weight_initializer = tf.keras.initializers.GlorotNormal(seed=42) 
    output_bias = tf.keras.initializers.Constant(initial_bias)
    input_word_ids = tf.keras.layers.Input(
        shape=(max_len,), dtype=tf.int32, name="input_word_ids"
    )
    sequence_output = transformer(input_word_ids)[0]
    cls_token = sequence_output[:, 0, :]
    net = tf.keras.layers.Dropout(0.2)(cls_token)
    dense1 = tf.keras.layers.Dense(256, kernel_initializer='ones',)(net)
    out = tf.keras.layers.Dense(1, activation="sigmoid",
                                kernel_initializer=weight_initializer, 
                                bias_initializer=output_bias)(dense1)
    model = tf.keras.models.Model(inputs=input_word_ids, outputs=out)
    model.compile(
        tf.keras.optimizers.Adam(lr=LEARNING_RATE),
        loss="binary_crossentropy",
        metrics=METRICS
    )
    return model


#combined model (as in Ostendorff et al. 2019)
def combined_model_test(transformer, max_len=MAXLEN, metrics=METRICS):
  output_bias = tf.keras.initializers.Constant(initial_bias)

  #input for bert model
  in_bert = tf.keras.layers.Input(
        shape=(max_len,), dtype=tf.int32, name="in_bert"
    )
  #input the input to the bert model
  sequence_output = transformer(in_bert)[0]
  #take out the cls token from the bert model
  cls_token = sequence_output[:, 0, :]
  
  #input for the mlp
  in_mlp = keras.Input(shape=(6, ))
  #concat result from bert and first mlp layer
  concatted = tf.keras.layers.concatenate([cls_token, in_mlp])
  #dense layer with concatted input
  layer1 = Dense(774,activation='relu',kernel_initializer='random_normal',kernel_regularizer=regularizers.L2(REGULARIZATION))(concatted)
  #dropout for regularization
  dropout1 = tf.keras.layers.Dropout(0.2)(layer1)
  #second dense layer with concatted input
  layer2 = Dense(774,activation='relu',kernel_initializer='random_normal')(dropout1)
  #dropout for regularization
  dropout2 = tf.keras.layers.Dropout(0.2)(layer2)
  #third dense layer with concatted input
  layer3 = Dense(512,activation='relu',kernel_initializer='random_normal')(dropout2)
  #sigmoid for output
  out_all = Dense(1,activation='sigmoid',kernel_initializer='random_normal',bias_initializer=output_bias)(layer3) 

  model = tf.keras.models.Model(inputs=[in_bert,in_mlp], outputs=out_all)
  model.compile(
        tf.keras.optimizers.Adam(lr=LEARNING_RATE),
        loss="binary_crossentropy",
        metrics = metrics
    )
  return model

from keras.layers import Activation, Dense
from tensorflow import keras
from keras.utils.vis_utils import plot_model
#transform idea text to vector with maxlength attribute, shorter ideas get padded to max_length
def preprocess_text(data):
    """ take texts and prepare as input features for BERT 
    """
    input_ids = []
    # For every sentence...
    for comment in data:
        encoded_sent = tokenizer.encode_plus(
            
            text=comment,
            add_special_tokens=True,  # Add `[CLS]` and `[SEP]`
            max_length=MAXLEN,  # Max length to truncate/pad
            pad_to_max_length=True,  # Pad sentence to max length
            return_attention_mask=False,  # attention mask not needed for our task
            return_token_type_ids=False
        )
        # Add the outputs to the lists
        input_ids.append(encoded_sent.get("input_ids"))
    return input_ids

scaler = StandardScaler()

#call preprocess_text to transform text in data to vectors for bert classification
X_bert = np.array(preprocess_text(df["Cleaned_Idea_Description"]))

#create data for mlp classification
X_mlp = np.array(df[['Likes','No of Comments','Voters','Visitors','lenNumber','wordNumber']])

#transform and normalise data for better classification
scaler.fit_transform(X_mlp)
X_mlp = scaler.transform(X_mlp)
X_mlp = np.clip(X_mlp, -5, 5)

#create labels dataframe
Y = np.array(df['top_ideas'])

#5 fold corssvalidation on dataset, the random state is only to ensure replicability, stratified fold is used in order to mitigate the unbalanced dataset
kf = StratifiedKFold(n_splits=5,random_state=11,shuffle=True)
kf.get_n_splits(X_bert,Y)

#arrays in order to save metrics through all 5 runs
histories_bert = []
histories_mlp = []
test_preds_bert_array = []
test_preds_mlp_array = []
ensemble_preds_array = []
train_labels = []
test_labels = []

# Loop over the dataset to create seprate folds
for train_index, test_index in kf.split(X_bert,Y):
    
    #create datasets for this run from all data 
    X_bert_train, X_bert_test = X_bert[train_index], X_bert[test_index]
    X_mlp_train, X_mlp_test = X_mlp[train_index], X_mlp[test_index]
    y_train, y_test = Y[train_index], Y[test_index]

    #print model parameters
    steps_per_epoch = int(np.floor((len(X_bert_train) / BATCH_SIZE)))
    print(
      f"Model Params:\nbatch_size: {BATCH_SIZE}\nEpochs: {EPOCHS}\n"
      f"Step p. Epoch: {steps_per_epoch}\n"
      f"Learning rate: {LEARNING_RATE}"
    )
    

    #append the labels to the arrays
    train_labels.append(y_train)
    test_labels.append(y_test)

    # Create a new bert and mlp model to be trained in this run
    with strategy.scope():
      distilBERT = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)
      #smallBERT = TFBertModel.from_pretrained("google/bert_uncased_L-4_H-512_A-8",from_pt=True)
      #BERT = TFBertModel.from_pretrained("bert-base-uncased")
      
      # Make DistilBERT layers untrainable
      for layer in distilBERT.layers:
        layer.trainable = False 
      

      for layer in distilBERT.layers:
        for attr in ['kernel_regularizer']:
          if hasattr(layer, attr):
            setattr(layer, attr, regularizer)
      
      
      model_bert = build_bert(distilBERT, max_len=MAXLEN)

    # train the models on the current fold
    history_bert = model_bert.fit(
        x=X_bert_train,
        y=y_train,
        class_weight=class_weight,
        batch_size=BATCH_SIZE,
        epochs=10,
        steps_per_epoch=steps_per_epoch,
        validation_data=[X_bert_test, y_test],
        verbose=1,
    )


    with strategy.scope():

      # Make DistilBERT layers trainable
      for layer in distilBERT.layers:
        layer.trainable = True 
      model_bert.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-6), 
              loss="binary_crossentropy",
              metrics=METRICS)
      
    history_bert2 = model_bert.fit(
        x=X_bert_train,
        y=y_train,
        class_weight=class_weight,
        batch_size=BATCH_SIZE,
        epochs=EPOCHS,
        steps_per_epoch=steps_per_epoch,
        validation_data=[X_bert_test, y_test],
        verbose=1,
        callbacks = [EarlyStoppingAtMinLoss()]
    )


    history_mlp = model_mlp.fit(
        x=X_mlp_train,
        y=y_train, 
        epochs=100, 
        validation_data=[X_mlp_test,y_test],
        class_weight=class_weight,
        callbacks=EarlyStoppingAtMinLoss_mlp()
    )
    #add histories of bert and mlp model to arrays
    histories_mlp.append(history_mlp)
    histories_bert.append(history_bert2)

    #test trained models on validation dataset and save results to arrays
    test_preds_bert = model_bert.predict(X_bert_test)
    test_preds_bert_array.append(test_preds_bert)
    test_preds_mlp = model_mlp.predict(X_mlp_test)
    test_preds_mlp_array.append(test_preds_mlp)
    
    #create new model as ensemle model from the bert and mlp model (as in Ammar & Rania, 2021)
    models = [model_bert, model_mlp]
    model_input_bert = tf.keras.Input(shape=(MAXLEN, ))
    model_input_mlp = tf.keras.Input(shape=(6, ))
    model_outputs = [model_bert(model_input_bert), model_mlp(model_input_mlp)]
    ensemble_output = tf.keras.layers.Average()(model_outputs)
    ensemble_model = tf.keras.Model(inputs=[model_input_bert, model_input_mlp], outputs=ensemble_output)

    #test trained ensemle model on validation dataset and seve results to array
    test_preds_ensemble = ensemble_model.predict([X_bert_test,X_mlp_test])
    ensemble_preds_array.append(test_preds_ensemble)

colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

#function to get roc curve from prediction and labels
def plot_roc(name, labels, predictions, **kwargs):
    fp, tp, _ = sk.metrics.roc_curve(labels, predictions)
    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)
    plt.xlabel('False positives [%]')
    plt.ylabel('True positives [%]')
    plt.xlim([-0.5,100.5])
    plt.ylim([-0.5,100.5])
    plt.grid(True)
    ax = plt.gca()
    ax.set_aspect('equal')

#loop over all 5 runs and create rocs of all 3 models for each run on same plot
for x in range(len(test_labels)):
    plot_roc("bert", test_labels[x], test_preds_bert_array[x], color="blue", linestyle='--')
    plot_roc("mlp", test_labels[x], test_preds_mlp_array[x], color="red", linestyle='--')
    plot_roc("ensemle", test_labels[x], ensemble_preds_array[x], color="green", linestyle='--')
    plt.legend(loc='lower right');
    plt.savefig("model_{}_all.png".format(x))
    plt.close()
    plt.cla()
    plt.clf()

#crate the roc of the 5 bert models on same plot
plot_roc("model1", test_labels[0], test_preds_bert_array[0], color=colors[0], linestyle='--')
plot_roc("model2", test_labels[1], test_preds_bert_array[1], color=colors[1], linestyle='--')
plot_roc("model3", test_labels[2], test_preds_bert_array[2], color=colors[2], linestyle='--')
plot_roc("model4", test_labels[3], test_preds_bert_array[3], color=colors[3], linestyle='--')
plot_roc("model5", test_labels[3], test_preds_bert_array[3], color=colors[3], linestyle='--')
plt.legend(loc='lower right');
plt.savefig('bert_all.png')

plt.close()
plt.cla()
plt.clf()

#crate the roc of the 5 mlp models on same plot
plot_roc("model1", test_labels[0], test_preds_mlp_array[0], color=colors[0], linestyle='--')
plot_roc("model2", test_labels[1], test_preds_mlp_array[1], color=colors[1], linestyle='--')
plot_roc("model3", test_labels[2], test_preds_mlp_array[2], color=colors[2], linestyle='--')
plot_roc("model4", test_labels[3], test_preds_mlp_array[3], color=colors[3], linestyle='--')
plot_roc("model5", test_labels[3], test_preds_mlp_array[3], color=colors[3], linestyle='--')
plt.legend(loc='lower right');
plt.savefig('mlp_all.png')

plt.close()
plt.cla()
plt.clf()

#crate the roc of the 5 ensemble models on same plot
plot_roc("model1", test_labels[0], ensemble_preds_array[0], color=colors[0], linestyle='--')
plot_roc("model2", test_labels[1], ensemble_preds_array[1], color=colors[1], linestyle='--')
plot_roc("model3", test_labels[2], ensemble_preds_array[2], color=colors[2], linestyle='--')
plot_roc("model4", test_labels[3], ensemble_preds_array[3], color=colors[3], linestyle='--')
plot_roc("model5", test_labels[3], ensemble_preds_array[3], color=colors[3], linestyle='--')
plt.legend(loc='lower right');
plt.savefig('ensemle_all.png')

plt.close()
plt.cla()
plt.clf()

#function to plot confusion matrix
def plot_cm(labels, predictions, p=0.5):
    cm = confusion_matrix(labels, predictions > p)
    plt.figure(figsize=(5, 5))
    sns.heatmap(cm, annot=True, fmt="d")
    plt.title('Confusion matrix @{:.2f}'.format(p))
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')


#loop over all runs and create the confusion matrix for each bert model
for x in range(len(test_labels)):
    plot_cm(test_labels[x], test_preds_bert_array[x])
    plt.savefig("model_{}_bert_cm.png".format(x))

#loop over all runs and create the confusion matrix for each mlp model
for x in range(len(test_labels)):
    plot_cm(test_labels[x], test_preds_mlp_array[x])
    plt.savefig("model_{}_mlp_cm.png".format(x))

#loop over all runs and create the confusion matrix for each ensemble model
for x in range(len(test_labels)):
    plot_cm(test_labels[x], ensemble_preds_array[x])
    plt.savefig("model_{}_ensemble_cm.png".format(x))

# figure, axis = plt.subplots(2, 3)
# figure.tight_layout()
#
# axis[0, 0].plot(history.history['accuracy'])
# axis[0, 0].plot(history.history['val_accuracy'])
# axis[0, 0].set_title('model accuracy')
# axis[0, 0].set_ylabel('accuracy')
# axis[0, 0].set_xlabel('epoch')
# axis[0, 0].legend(['train', 'val'], loc='upper left')
