# -*- coding: utf-8 -*-
"""ensemble_current.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r0SXWJKSbgjOesyJXCs7A7ATN8b8da-g
"""


from sklearn.preprocessing import MinMaxScaler
import os
from sklearn.metrics import confusion_matrix
import keras
import sklearn
import tempfile
from sklearn.model_selection import StratifiedKFold
import tensorflow as tf
from sklearn.preprocessing import *
import pandas as pd
import matplotlib as mpl
import re
import matplotlib.pyplot as plt
from keras import backend as kf
import numpy as np
import seaborn as sns
import string
from sklearn.utils import class_weight
from sklearn.model_selection import train_test_split
import os
from transformers import BertTokenizer, TFBertModel, BertConfig
from transformers import DebertaTokenizer, TFDebertaForMaskedLM
from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig
from keras import backend as K
import inflect
from keras import regularizers
import sklearn as sk
from keras.layers import Activation, Dense
from tensorflow import keras
from keras.utils.vis_utils import plot_model
from focal_loss import BinaryFocalLoss

# colors for confusion matrix
mpl.rcParams['figure.figsize'] = (12, 10)
colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

# load tokenizer
# tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
#tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")



# load dataset
df = pd.read_csv('jti_dataset_refined.csv')

# define strategy for gpu distributed workload sclaes with number of gpus available
# strategy = tf.distribute.MirroredStrategy()
# strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
# gpus = tf.config.list_logical_devices('GPU')
tf.config.set_soft_device_placement(True)
strategy = strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
# define maxlength of bert vector
MAXLEN = 200


# copy dataset to have one original

def text_clean(x):
    ### Light
    x = x.lower()  # lowercase everything
    x = x.encode('ascii', 'ignore').decode()  # remove unicode characters
    x = re.sub(r'https*\S+', ' ', x)  # remove links
    x = re.sub(r'http*\S+', ' ', x)
    # cleaning up text
    return x


print(df['Cleaned_Idea_Description'][2314])
df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(text_clean)
print(df['Cleaned_Idea_Description'][2314])

# import the inflect library

p = inflect.engine()


# convert number into words
def convert_number(text):
    # split string into list of words
    temp_str = text.split()
    # initialise empty list
    new_string = []

    for word in temp_str:
        # if word is a digit, convert the digit
        # to numbers and append into the new_string list
        if word.isdigit():
            temp = p.number_to_words(word)
            new_string.append(temp)

        # append the word as it is
        else:
            new_string.append(word)

    # join the words of new_string to form a string
    temp_str = ' '.join(new_string)
    return temp_str


df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(convert_number)
print(df['Cleaned_Idea_Description'][2314])


# remove punctuation
def remove_punctuation(text):
    translator = str.maketrans('', '', string.punctuation)
    return text.translate(translator)


# remove whitespace from text
def remove_whitespace(text):
    return " ".join(text.split())


df['Cleaned_Idea_Description'] = df['Cleaned_Idea_Description'].apply(remove_whitespace)
print(df['Cleaned_Idea_Description'][2314])

# ratio of good to bad ideas
neg, pos = np.bincount(df['top_ideas'])
total = neg + pos
print('Examples:\n    Total: {}\n    Positive: {} ({:.2f}% of total)\n'.format(
    total, pos, 100 * pos / total))

weight_for_0 = (1 / neg) * (total / 2.0)
weight_for_1 = ((1 / pos) * (total / 2.0))

# calculate class weights
class_weight = {0: weight_for_0, 1: weight_for_1}
# calculate class weights
print('Weight for class 0: {:.2f}'.format(weight_for_0))
print('Weight for class 1: {:.2f}'.format(weight_for_1))

# calculate initial weights
initial_bias = np.log([pos / neg])
# colors for confusion matrix
colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

# hyperparameters for training
MAXLEN = MAXLEN
BATCH_SIZE_PER_REPLICA = 16
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
EPOCHS = 50
DROPOUT = 0.3
LEARNING_RATE = 3e-5
REGULARIZATION = 0.01
DATA_LENGTH = len(df)


class CustomCallback(keras.callbacks.Callback):
    def on_train_begin(self, logs=None):
        keys = list(logs.keys())
        print("Starting training; got log keys: {}".format(keys))

    def on_train_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop training; got log keys: {}".format(keys))

    def on_epoch_begin(self, epoch, logs=None):
        keys = list(logs.keys())
        print("Start epoch {} of training; got log keys: {}".format(epoch, keys))

    def on_epoch_end(self, epoch, logs=None):
        keys = list(logs.keys())
        print("End epoch {} of training; got log keys: {}".format(epoch, keys))

    def on_test_begin(self, logs=None):
        keys = list(logs.keys())
        print("Start testing; got log keys: {}".format(keys))

    def on_test_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop testing; got log keys: {}".format(keys))

    def on_predict_begin(self, logs=None):
        keys = list(logs.keys())
        print("Start predicting; got log keys: {}".format(keys))

    def on_predict_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop predicting; got log keys: {}".format(keys))

    def on_train_batch_begin(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Training: start of batch {}; got log keys: {}".format(batch, keys))

    def on_train_batch_end(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Training: end of batch {}; got log keys: {}".format(batch, keys))

    def on_test_batch_begin(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Evaluating: start of batch {}; got log keys: {}".format(batch, keys))

    def on_test_batch_end(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Evaluating: end of batch {}; got log keys: {}".format(batch, keys))

    def on_predict_batch_begin(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Predicting: start of batch {}; got log keys: {}".format(batch, keys))

    def on_predict_batch_end(self, batch, logs=None):
        keys = list(logs.keys())
        print("...Predicting: end of batch {}; got log keys: {}".format(batch, keys))


class EarlyStoppingAtMinLoss(keras.callbacks.Callback):
    """Stop training when the loss is at its min, i.e. the loss stops decreasing.

  Arguments:
      patience: Number of epochs to wait after min has been hit. After this
      number of no improvement, training stops.
  """

    def __init__(self, patience=0):
        super(EarlyStoppingAtMinLoss, self).__init__()
        self.patience = patience
        self.epoch = 0
        self.sp = []
        self.recall = []
        self.accuracy = []
        self.sp_val = []
        self.recall_val = []
        self.accuracy_val = []
        # best_weights to store the weights at which the minimum loss occurs.
        self.best_weights = None

    def on_train_begin(self, logs=None):
        # The number of epoch it has waited when loss is no longer minimum.
        self.wait = 0
        # The epoch the training stops at.
        self.stopped_epoch = 0
        # Initialize the best as infinity.
        self.best = 0

    def on_epoch_end(self, epoch, logs=None):
        self.sp.append(logs.get("special_metric"))
        self.recall.append(logs.get("recall"))
        self.accuracy.append(logs.get("accuracy"))

        self.epoch = epoch

        self.sp_val.append(logs.get("val_special_metric"))
        self.recall_val.append(logs.get("val_recall"))
        self.accuracy_val.append(logs.get("val_accuracy"))
        print("recall_train:\n")
        print(self.recall)
        print("recall_val:\n")
        print(self.recall_val)

        try:
            if self.sp_val[epoch] < self.sp_val[epoch - 1]:
                if self.recall[epoch] < 0.8 or self.accuracy[epoch] < 0.8:
                    pass
                elif self.recall_val[epoch] > self.recall_val[epoch - 1]:
                    pass
                else:
                    if self.sp_val[epoch - 1] > self.sp_val[epoch - 2] and self.sp_val[epoch] > self.sp_val[epoch - 2]:
                        pass
                    else:
                        self.model.stop_training = True
                        self.stopped_epoch = epoch
                        print("Restoring model weights from the end of the best epoch.")
                        self.model.set_weights(self.best_weights)
            else:
                if self.sp_val[epoch] > self.best:
                    self.best_weights = self.model.get_weights()
        except TypeError:
            print("first_round")

    def on_train_end(self, logs=None):
        if self.stopped_epoch > 0:
            print("Epoch %05d: early stopping\n" % (self.stopped_epoch + 1))


class EarlyStoppingAtMinLoss_mlp(keras.callbacks.Callback):
    """Stop training when the loss is at its min, i.e. the loss stops decreasing.

  Arguments:
      patience: Number of epochs to wait after min has been hit. After this
      number of no improvement, training stops.
  """

    def __init__(self, patience=0):
        super(EarlyStoppingAtMinLoss_mlp, self).__init__()
        self.patience = patience
        self.epoch = 0
        self.sp = []
        self.recall = []
        self.accuracy = []
        self.sp_val = []
        self.recall_val = []
        self.accuracy_val = []
        # best_weights to store the weights at which the minimum loss occurs.
        self.best_weights = None

    def on_train_begin(self, logs=None):
        # The number of epoch it has waited when loss is no longer minimum.
        self.wait = 0
        # The epoch the training stops at.
        self.stopped_epoch = 0
        # Initialize the best as infinity.
        self.best = 0

    def on_epoch_end(self, epoch, logs=None):
        self.sp.append(logs.get("special_metric"))
        self.recall.append(logs.get("recall"))
        self.accuracy.append(logs.get("accuracy"))

        self.epoch = epoch

        self.sp_val.append(logs.get("val_special_metric"))
        self.recall_val.append(logs.get("val_recall"))
        self.accuracy_val.append(logs.get("val_accuracy"))
        print("recall_train:\n")
        print(self.recall)
        print("recall_val:\n")
        print(self.recall_val)

        try:
            if self.sp_val[epoch] < self.sp_val[epoch - 1]:
                if self.recall[epoch] < 0.75 or self.accuracy[epoch] < 0.75:
                    pass
                elif self.recall_val[epoch] > self.recall_val[epoch - 1]:
                    pass
                else:
                    if self.sp_val[epoch - 1] > self.sp_val[epoch - 2] and self.sp_val[epoch] > self.sp_val[epoch - 2]:
                        pass
                    else:
                        self.model.stop_training = True
                        self.stopped_epoch = epoch
                        print("Restoring model weights from the end of the best epoch.")
                        self.model.set_weights(self.best_weights)
            else:
                if self.sp_val[epoch] > self.best:
                    self.best_weights = self.model.get_weights()
        except TypeError:
            print("first_round")

    def on_train_end(self, logs=None):
        if self.stopped_epoch > 0:
            print("Epoch %05d: early stopping\n" % (self.stopped_epoch + 1))


class Special_Metric(tf.keras.metrics.Metric):

    def __init__(self, name='special_metric', **kwargs):
        super(Special_Metric, self).__init__(name=name, **kwargs)
        self.true_positives = self.add_weight(name='tp', initializer='zeros')
        self.false_positives = self.add_weight(name='fp', initializer='zeros')
        self.true_negatives = self.add_weight(name='tn', initializer='zeros')
        self.false_negatives = self.add_weight(name='fn', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(y_true, tf.float32)
        tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))
        fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))
        fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))

        self.true_positives.assign_add(tp)
        self.false_positives.assign_add(fp)
        self.true_negatives.assign_add(tn)
        self.false_negatives.assign_add(fn)

    def result(self):
        recall = self.true_positives / (self.true_positives + self.false_negatives)
        accuracy = (self.true_positives + self.true_negatives) / (
                self.true_positives + self.false_negatives + self.true_negatives + self.false_positives)
        special = (1.2 * recall + accuracy) * 0.45
        return special

    def reset_state(self):
        self.true_positives.assign(0)
        self.false_positives.assign(0)
        self.true_negatives.assign(0)
        self.false_negatives.assign(0)


class F1(tf.keras.metrics.Metric):

    def __init__(self, name='F1', **kwargs):
        super(F1, self).__init__(name=name, **kwargs)
        self.true_positives = self.add_weight(name='tp', initializer='zeros')
        self.false_positives = self.add_weight(name='fp', initializer='zeros')
        self.true_negatives = self.add_weight(name='tn', initializer='zeros')
        self.false_negatives = self.add_weight(name='fn', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(y_true, tf.float32)
        tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))
        fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))
        fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))

        self.true_positives.assign_add(tp)
        self.false_positives.assign_add(fp)
        self.true_negatives.assign_add(tn)
        self.false_negatives.assign_add(fn)

    def result(self):
        recall = self.true_positives / (self.true_positives + self.false_negatives)
        precision = self.true_positives / (self.true_positives + self.false_positives)
        f1 = 2 * precision * recall / (precision + recall)
        return f1

    def reset_state(self):
        self.true_positives.assign(0)
        self.false_positives.assign(0)
        self.true_negatives.assign(0)
        self.false_negatives.assign(0)


with strategy.scope():
    METRICS = [
        keras.metrics.TruePositives(name='tp'),
        keras.metrics.FalsePositives(name='fp'),
        keras.metrics.TrueNegatives(name='tn'),
        keras.metrics.FalseNegatives(name='fn'),
        keras.metrics.Recall(name='recall'),
        keras.metrics.BinaryAccuracy(name='accuracy'),
        tf.keras.metrics.Precision(name='precision'),
        keras.metrics.AUC(name='auc'),
        keras.metrics.AUC(name='prc', curve='PR'),
        Special_Metric()
    ]

DISTILBERT_DROPOUT = 0.3
DISTILBERT_ATT_DROPOUT = 0.3
# Configure DistilBERT's initialization (increase dropout compared to standard model)
config = DistilBertConfig(dropout=DISTILBERT_DROPOUT,
                          attention_dropout=DISTILBERT_ATT_DROPOUT,
                          output_hidden_states=True)


DEBERTA_DROPOUT = 0.3
DEBERTA_ATT_DROPOUT = 0.3
# Configure DistilBERT's initialization (increase dropout compared to standard model)
config_bert= BertConfig(dropout=DEBERTA_DROPOUT,
                               attention_dropout=DEBERTA_ATT_DROPOUT,
                               output_hidden_states=True)



# bert for text classification (as in Devlin et al. 2018)
def build_bert(transformer,seed, max_len=MAXLEN):
    weight_initializer = tf.keras.initializers.GlorotNormal(seed=seed)
    output_bias = tf.keras.initializers.Constant(initial_bias)
    input_word_ids = tf.keras.layers.Input(
        shape=(max_len,), dtype=tf.int32, name="input_word_ids"
    )
    sequence_output = transformer(input_word_ids)[0]
    cls_token = sequence_output[:, 0, :]
    net = tf.keras.layers.Dropout(0.2)(cls_token)
    dense1 = tf.keras.layers.Dense(256, kernel_initializer='ones', )(net)
    out = tf.keras.layers.Dense(1, activation="sigmoid",
                                kernel_initializer=weight_initializer,
                                bias_initializer=output_bias)(dense1)
    model = tf.keras.models.Model(inputs=input_word_ids, outputs=out)
    model.compile(
        tf.keras.optimizers.Adam(lr=LEARNING_RATE),
        loss=BinaryFocalLoss(gamma=2),
        metrics=METRICS
    )
    return model


#mlp for metadata classification
def build_mlp(metrics=METRICS):
    output_bias = tf.keras.initializers.Constant(initial_bias)
    input = keras.Input(shape=(6, ))
    layer1= Dense(128, activation='relu', 
                kernel_initializer='random_normal')(input)
    dropout1 = keras.layers.Dropout(0.2)(layer1)
    layer2 = Dense(64,activation='relu',kernel_initializer='random_normal')(dropout1)
    dropout2 = keras.layers.Dropout(0.2)(layer2)
    layer3 = Dense(32,activation='relu',kernel_initializer='random_normal')(dropout2)
    output = Dense(1,activation='sigmoid',kernel_initializer='random_normal',bias_initializer=output_bias)(layer3)
    model = tf.keras.models.Model(inputs=input, outputs=output)
    model.compile(
      optimizer=keras.optimizers.Adam(learning_rate=1e-3),
      loss=keras.losses.BinaryCrossentropy(),
      metrics=metrics)
    return model




#mlp for metadata classification
def build_mlp_1(metrics=METRICS):
    output_bias = tf.keras.initializers.Constant(initial_bias)
    input = keras.Input(shape=(6, ))
    layer2 = Dense(64,activation='relu',kernel_initializer='random_normal')(input)
    output = Dense(1,activation='sigmoid',kernel_initializer='random_normal',bias_initializer=output_bias)(layer2)
    model = tf.keras.models.Model(inputs=input, outputs=output)
    model.compile(
      optimizer=keras.optimizers.Adam(learning_rate=1e-3),
      loss=keras.losses.BinaryCrossentropy(),
      metrics=metrics)
    return model


#mlp for metadata classification
def build_mlp_2(metrics=METRICS):
    output_bias = tf.keras.initializers.Constant(initial_bias)
    input = keras.Input(shape=(6, ))
    layer1= Dense(128, activation='relu', 
                kernel_initializer='random_normal')(input)
    dropout1 = keras.layers.Dropout(0.3)(layer1)
    layer3 = Dense(32,activation='relu',kernel_initializer='random_normal')(dropout1)
    output = Dense(1,activation='sigmoid',kernel_initializer='random_normal',bias_initializer=output_bias)(layer3)
    model = tf.keras.models.Model(inputs=input, outputs=output)
    model.compile(
      optimizer=keras.optimizers.Adam(learning_rate=1e-3),
      loss=keras.losses.BinaryCrossentropy(),
      metrics=metrics)
    return model



# combined model (as in Ostendorff et al. 2019) (a.t.m. performs worse than the ensemble model)
def combined_model_test(transformer, max_len=MAXLEN, metrics=METRICS):
    output_bias = tf.keras.initializers.Constant(initial_bias)

    # input for bert model
    in_bert = tf.keras.layers.Input(
        shape=(max_len,), dtype=tf.int32, name="in_bert"
    )
    # input the input to the bert model
    sequence_output = transformer(in_bert)[0]
    # take out the cls token from the bert model
    cls_token = sequence_output[:, 0, :]

    # input for the mlp
    in_mlp = keras.Input(shape=(6,))
    # concat result from bert and first mlp layer
    concatted = tf.keras.layers.concatenate([cls_token, in_mlp])
    # dense layer with concatted input
    layer1 = Dense(774, activation='relu', kernel_initializer='random_normal',
                   kernel_regularizer=regularizers.L2(REGULARIZATION))(concatted)
    # dropout for regularization
    dropout1 = tf.keras.layers.Dropout(0.2)(layer1)
    # second dense layer with concatted input
    layer2 = Dense(774, activation='relu', kernel_initializer='random_normal')(dropout1)
    # dropout for regularization
    dropout2 = tf.keras.layers.Dropout(0.2)(layer2)
    # third dense layer with concatted input
    layer3 = Dense(512, activation='relu', kernel_initializer='random_normal')(dropout2)
    # sigmoid for output
    out_all = Dense(1, activation='sigmoid', kernel_initializer='random_normal', bias_initializer=output_bias)(layer3)

    model = tf.keras.models.Model(inputs=[in_bert, in_mlp], outputs=out_all)
    model.compile(
        tf.keras.optimizers.Adam(lr=LEARNING_RATE),
        loss="binary_crossentropy",
        metrics=metrics
    )
    return model





# transform idea text to vector with maxlength attribute, shorter ideas get padded to max_length
def preprocess_text(data):
    """ take texts and prepare as input features for BERT 
    """
    input_ids = []
    # For every sentence...
    for comment in data:
        encoded_sent = tokenizer.encode_plus(

            text=comment,
            add_special_tokens=True,  # Add `[CLS]` and `[SEP]`
            max_length=MAXLEN,  # Max length to truncate/pad
            pad_to_max_length=True,  # Pad sentence to max length
            return_attention_mask=False,  # attention mask not needed for our task
            return_token_type_ids=False
        )
        # Add the outputs to the lists
        input_ids.append(encoded_sent.get("input_ids"))
    return input_ids


scaler = StandardScaler()

import tensorflow as tf
from tensorflow import keras


class HardMax(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(HardMax, self).__init__(**kwargs)

    def call(self, inputs):
        preds_pos = []
        preds_neg = []
        if inputs[0] >= 0.5:
            preds_pos.append(inputs[0])
        else:
            preds_neg.append(inputs[0])
        if inputs[1] >= 0.5:
            preds_pos.append(inputs[1])
        else:
            preds_neg.append(inputs[1])
        if inputs[2] >= 0.5:
            preds_pos.append(inputs[2])
        else:
            preds_neg.append(inputs[2])
        if len(preds_pos) > len(preds_neg):
            return sum(preds_pos) / len(preds_pos)
        else:
            return sum(preds_neg) / len(preds_neg)

        

# call preprocess_text to transform text in data to vectors for bert classification
X_bert = np.array(preprocess_text(df["Cleaned_Idea_Description"]))

# create data for mlp classification
X_mlp = np.array(df[['Likes', 'No of Comments', 'Voters', 'Visitors', 'lenNumber', 'wordNumber']])

# transform and normalise data for better classification
scaler.fit_transform(X_mlp)
X_mlp = scaler.transform(X_mlp)
X_mlp = np.clip(X_mlp, -5, 5)

# create labels dataframe
Y = np.array(df['top_ideas'])

# 5 fold corssvalidation on dataset, the random state is only to ensure replicability, stratified fold is used in order to mitigate the unbalanced dataset
kf = StratifiedKFold(n_splits=5, random_state=11, shuffle=True)
kf.get_n_splits(X_bert, Y)

# arrays in order to save metrics through all 5 runs
histories_bert = []
histories_mlp = []
test_preds_bert_array_0 = []
test_preds_bert_array_1 = []
test_preds_bert_array_2 = []
test_preds_mlp_array_0 = []
test_preds_mlp_array_1 = []
test_preds_mlp_array_2 = []
ensemble_bert_preds_array = []
ensemble_mlp_preds_array = []
ensemble_final_preds_array = []
train_labels = []
test_labels = []

regularizer = tf.keras.regularizers.l2(REGULARIZATION)

# Loop over the dataset to create seprate folds
for train_index, test_index in kf.split(X_bert, Y):

    # create datasets for this run from all data
    X_bert_train, X_bert_test = X_bert[train_index], X_bert[test_index]
    X_mlp_train, X_mlp_test = X_mlp[train_index], X_mlp[test_index]
    y_train, y_test = Y[train_index], Y[test_index]

    # print model parameters
    steps_per_epoch = int(np.floor((len(X_bert_train) / BATCH_SIZE)))
    print(
        f"Model Params:\nbatch_size: {BATCH_SIZE}\nEpochs: {EPOCHS}\n"
        f"Step p. Epoch: {steps_per_epoch}\n"
        f"Learning rate: {LEARNING_RATE}"
    )

    # append the labels to the arrays
    train_labels.append(y_train)
    test_labels.append(y_test)

    # Create a new bert and mlp model to be trained in this run
    with strategy.scope():
        BERT1 = TFBertModel.from_pretrained("bert-base-uncased", config=config_bert)
        BERT2 = TFBertModel.from_pretrained("bert-base-uncased", config=config_bert)
        BERT = TFBertModel.from_pretrained("bert-base-uncased", config=config_bert)
        model_mlp_0 = build_mlp()
        model_mlp_1 = build_mlp_1()
        model_mlp_2 = build_mlp_2()

        # Make DistilBERT layers untrainable
        for layer in BERT.layers:
            layer.trainable = False
        for layer in BERT1.layers:
            layer.trainable = False
        for layer in BERT2.layers:
            layer.trainable = False

        for layer in BERT1.layers:
            for attr in ['kernel_regularizer']:
                if hasattr(layer, attr):
                    setattr(layer, attr, regularizer)
        for layer in BERT.layers:
            for attr in ['kernel_regularizer']:
                if hasattr(layer, attr):
                    setattr(layer, attr, regularizer)
        for layer in BERT2.layers:
            for attr in ['kernel_regularizer']:
                if hasattr(layer, attr):
                    setattr(layer, attr, regularizer)

        model_bert_0 = build_bert(BERT, 3, max_len=MAXLEN)
        model_bert_1 = build_bert(BERT1, 22, max_len=MAXLEN)
        model_bert_2 = build_bert(BERT2, 37, max_len=MAXLEN)

    # train only the mlp layers of the bert model, leaving the pretrained layers unchanged
    history_bert = model_bert_0.fit(x=X_bert_train, y=y_train, class_weight=class_weight, batch_size=BATCH_SIZE,
                                    epochs=10, steps_per_epoch=steps_per_epoch, validation_data=[X_bert_test, y_test],
                                    verbose=1, )
    history_bert = model_bert_1.fit(x=X_bert_train, y=y_train, class_weight=class_weight, batch_size=BATCH_SIZE,
                                    epochs=10, steps_per_epoch=steps_per_epoch, validation_data=[X_bert_test, y_test],
                                    verbose=1, )
    history_bert = model_bert_2.fit(x=X_bert_train, y=y_train, class_weight=class_weight, batch_size=BATCH_SIZE,
                                    epochs=10, steps_per_epoch=steps_per_epoch, validation_data=[X_bert_test, y_test],
                                    verbose=1, )

    history_mlp = model_mlp_0.fit(x=X_mlp_train, y=y_train, epochs=100, validation_data=[X_mlp_test, y_test],
                                  class_weight=class_weight, callbacks=EarlyStoppingAtMinLoss_mlp())
    history_mlp = model_mlp_1.fit(x=X_mlp_train, y=y_train, epochs=100, validation_data=[X_mlp_test, y_test],
                                  class_weight=class_weight, callbacks=EarlyStoppingAtMinLoss_mlp())
    history_mlp = model_mlp_2.fit(x=X_mlp_train, y=y_train, epochs=100, validation_data=[X_mlp_test, y_test],
                                  class_weight=class_weight, callbacks=EarlyStoppingAtMinLoss_mlp())

    with strategy.scope():
        # Make DistilBERT layers trainable
        for layer in BERT.layers:
            layer.trainable = True
        for layer in BERT1.layers:
            layer.trainable = True
        for layer in BERT2.layers:
            layer.trainable = True
        model_bert_0.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-6),
                             loss=BinaryFocalLoss(gamma=2),
                             metrics=METRICS)
        model_bert_1.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-6),
                             loss=BinaryFocalLoss(gamma=2),
                             metrics=METRICS)
        model_bert_2.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-6),
                             loss=BinaryFocalLoss(gamma=2),
                             metrics=METRICS)

    history_bert2 = model_bert_0.fit(x=X_bert_train, y=y_train, class_weight=class_weight, batch_size=BATCH_SIZE,
                                     epochs=50, steps_per_epoch=steps_per_epoch, validation_data=[X_bert_test, y_test],
                                     verbose=1, callbacks=[EarlyStoppingAtMinLoss()])
    history_bert2 = model_bert_1.fit(x=X_bert_train, y=y_train, class_weight=class_weight, batch_size=BATCH_SIZE,
                                     epochs=50, steps_per_epoch=steps_per_epoch, validation_data=[X_bert_test, y_test],
                                     verbose=1, callbacks=[EarlyStoppingAtMinLoss()])
    history_bert2 = model_bert_2.fit(x=X_bert_train, y=y_train, class_weight=class_weight, batch_size=BATCH_SIZE,
                                     epochs=50, steps_per_epoch=steps_per_epoch, validation_data=[X_bert_test, y_test],
                                     verbose=1, callbacks=[EarlyStoppingAtMinLoss()])

    # add histories of bert and mlp model to arrays
    # histories_mlp.append(history_mlp)
    # histories_bert.append(history_bert2)

    # test trained models on validation dataset and save results to arrays
    test_preds_bert = model_bert_0.predict(X_bert_test)
    test_preds_bert_array_0.append(test_preds_bert)
    test_preds_bert = model_bert_1.predict(X_bert_test)
    test_preds_bert_array_1.append(test_preds_bert)
    test_preds_bert = model_bert_2.predict(X_bert_test)
    test_preds_bert_array_2.append(test_preds_bert)

    test_preds_mlp = model_mlp_0.predict(X_mlp_test)
    test_preds_mlp_array_0.append(test_preds_mlp)
    test_preds_mlp = model_mlp_1.predict(X_mlp_test)
    test_preds_mlp_array_1.append(test_preds_mlp)
    test_preds_mlp = model_mlp_2.predict(X_mlp_test)
    test_preds_mlp_array_2.append(test_preds_mlp)

    # create new model as ensemle model from the bert and mlp model (as in Ammar & Rania, 2021)
    models_mlp = [model_mlp_0, model_mlp_1, model_mlp_2]
    model_input_mlp = tf.keras.Input(shape=(6,))
    model_outputs_mlp = [model_mlp_0(model_input_mlp), model_mlp_1(model_input_mlp), model_mlp_2(model_input_mlp)]
    ensemble_output_mlp = HardMax()(model_outputs_mlp)
    ensemble_model_mlp = tf.keras.Model(inputs=model_input_mlp, outputs=ensemble_output_mlp)

    models_bert = [model_bert_0, model_bert_1, model_bert_2]
    model_inputs_bert = tf.keras.Input(shape=(MAXLEN,))
    model_outputs_bert = [model_bert_0(model_inputs_bert), model_bert_1(model_inputs_bert),
                          model_bert_2(model_inputs_bert)]
    ensemble_output_bert = HardMax()(model_outputs_bert)
    ensemble_model_bert = tf.keras.Model(inputs=model_inputs_bert, outputs=ensemble_output_bert)

    # test trained ensemle model on validation dataset and seve results to array
    test_preds_ensemble = ensemble_model_mlp.predict(X_mlp_test)
    ensemble_mlp_preds_array.append(test_preds_ensemble)

    # test trained ensemle model on validation dataset and seve results to array
    test_preds_ensemble = ensemble_model_bert.predict(X_bert_test)
    ensemble_bert_preds_array.append(test_preds_ensemble)

    models_final = [ensemble_model_bert, ensemble_model_mlp]
    model_input_final_bert = tf.keras.Input(shape=(MAXLEN,))
    model_input_final_mlp = tf.keras.Input(shape=(6,))
    model_outputs_final = [ensemble_model_bert(model_input_final_bert), ensemble_model_mlp(model_input_final_mlp)]
    ensemble_output_final = tf.keras.layers.Average()(model_outputs_final)
    ensemble_model_final = tf.keras.Model(inputs=[model_input_final_bert, model_input_final_mlp],
                                          outputs=ensemble_output_final)

    test_preds_ensemble = ensemble_model_final.predict([X_bert_test, X_mlp_test])
    ensemble_final_preds_array.append(test_preds_ensemble)

threshholds = list(range(0, 101, 1))
threshholds = [x / 100.0 for x in threshholds]


def plot_roc(name, labels, predictions, **kwargs):
    fpr_array = []
    tpr_array = []
    for threshold in threshholds:
        current_preds = []
        for pred in predictions:
            if pred >= threshold:
                current_preds.append(1)
            else:
                current_preds.append(0)
        tp = 0
        fp = 0
        tn = 0
        fn = 0
        for l1, l2 in zip(current_preds, labels):
            if l1 == 1 and l2 == 0:
                fp += 1
            elif l1 == 1 and l2 == 1:
                tp += 1
            elif l1 == 0 and l2 == 0:
                tn += 1
            elif l1 == 0 and l2 == 1:
                fn += 1
        tpr = tp / (tp + fn)
        fpr = fp / (fp + tn)
        fpr_array.append(fpr)
        tpr_array.append(tpr)
    fpr_array = [x * 100.0 for x in fpr_array]
    tpr_array = [x * 100.0 for x in tpr_array]
    all_tp_arrays.append(tpr_array)
    all_fp_arrays.append(fpr_array)
    plt.plot(fpr_array, tpr_array, label=name, linewidth=2, **kwargs)
    plt.xlabel('False positives [%]')
    plt.ylabel('True positives [%]')
    plt.xlim([-0.5, 100.5])
    plt.ylim([-0.5, 100.5])
    plt.grid(True)
    ax = plt.gca()
    ax.set_aspect('equal')


def plot_roc_average(name, fpr_arrays, tpr_arrays, **kwargs):
    fpr_array = []
    tpr_array = []
    for x in range(len(fpr_arrays[0])):
        y = fpr_arrays[0][x] + fpr_arrays[1][x] + fpr_arrays[2][x] + fpr_arrays[3][x] + fpr_arrays[4][x]
        y = y / 5
        fpr_array.append(y)
        y = tpr_arrays[0][x] + tpr_arrays[1][x] + tpr_arrays[2][x] + tpr_arrays[3][x] + tpr_arrays[4][x]
        y = y / 5
        tpr_array.append(y)

    plt.plot(fpr_array, tpr_array, label=name, linewidth=2, **kwargs)
    plt.xlabel('False positives [%]')
    plt.ylabel('True positives [%]')
    plt.xlim([-0.5, 100.5])
    plt.ylim([-0.5, 100.5])
    plt.grid(True)
    ax = plt.gca()
    ax.set_aspect('equal')


# crate the roc of the 5 bert models on same plot
all_fp_arrays = []
all_tp_arrays = []
plot_roc("model1", test_labels[0], ensemble_bert_preds_array[0], color=colors[0], linestyle='--')
plot_roc("model2", test_labels[1], ensemble_bert_preds_array[1], color=colors[1], linestyle='--')
plot_roc("model3", test_labels[2], ensemble_bert_preds_array[2], color=colors[2], linestyle='--')
plot_roc("model4", test_labels[3], ensemble_bert_preds_array[3], color=colors[3], linestyle='--')
plot_roc("model5", test_labels[4], ensemble_bert_preds_array[4], color=colors[4], linestyle='--')
plot_roc_average("average", all_fp_arrays, all_tp_arrays, color="black", linestyle='-')
plt.legend(loc='lower right');
plt.savefig('bert_ensemble_all.png')

plt.close()
plt.cla()
plt.clf()

# crate the roc of the 5 mlp models on same plot
all_fp_arrays = []
all_tp_arrays = []
plot_roc("model1", test_labels[0], ensemble_mlp_preds_array[0], color=colors[0], linestyle='--')
plot_roc("model2", test_labels[1], ensemble_mlp_preds_array[1], color=colors[1], linestyle='--')
plot_roc("model3", test_labels[2], ensemble_mlp_preds_array[2], color=colors[2], linestyle='--')
plot_roc("model4", test_labels[3], ensemble_mlp_preds_array[3], color=colors[3], linestyle='--')
plot_roc("model5", test_labels[4], ensemble_mlp_preds_array[4], color=colors[4], linestyle='--')
plot_roc_average("average", all_fp_arrays, all_tp_arrays, color="black", linestyle='-')
plt.legend(loc='lower right');
plt.savefig('mlp_ensemle_all.png')

plt.close()
plt.cla()
plt.clf()

# crate the roc of the 5 ensemble models on same plot
all_fp_arrays = []
all_tp_arrays = []
plot_roc("model1", test_labels[0], ensemble_final_preds_array[0], color=colors[0], linestyle='--')
plot_roc("model2", test_labels[1], ensemble_final_preds_array[1], color=colors[1], linestyle='--')
plot_roc("model3", test_labels[2], ensemble_final_preds_array[2], color=colors[2], linestyle='--')
plot_roc("model4", test_labels[3], ensemble_final_preds_array[3], color=colors[3], linestyle='--')
plot_roc("model5", test_labels[4], ensemble_final_preds_array[4], color=colors[4], linestyle='--')
plot_roc_average("average", all_fp_arrays, all_tp_arrays, color="black", linestyle='-')
plt.legend(loc='lower right');
plt.savefig('final_ensemle_all.png')

plt.close()
plt.cla()
plt.clf()
